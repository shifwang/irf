{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path+= ['/Users/ericxia/Documents/Research/iRF/irf/demo', '/Users/ericxia/anaconda/lib/python36.zip', '/Users/ericxia/anaconda/lib/python3.6', '/Users/ericxia/anaconda/lib/python3.6/lib-dynload', '/Users/ericxia/anaconda/lib/python3.6/site-packages', '/Users/ericxia/Documents/Research/iRF/irf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericxia/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ericxia/anaconda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import irf\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "import irf.ensemble.wrf as wrf\n",
    "from irf.ensemble import RandomForestClassifier\n",
    "from irf.ensemble.wrf import wrf_reg\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from irf import irf_utils\n",
    "from irf import irf_jupyter_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ericxia/anaconda/lib/python36.zip',\n",
       " '/Users/ericxia/anaconda/lib/python3.6',\n",
       " '/Users/ericxia/anaconda/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/ericxia/anaconda/lib/python3.6/site-packages',\n",
       " '/Users/ericxia/Documents/Research/iRF/irf',\n",
       " '/Users/ericxia/anaconda/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/ericxia/.ipython',\n",
       " '/Users/ericxia/Documents/Research/iRF/irf/demo',\n",
       " '/Users/ericxia/anaconda/lib/python36.zip',\n",
       " '/Users/ericxia/anaconda/lib/python3.6',\n",
       " '/Users/ericxia/anaconda/lib/python3.6/lib-dynload',\n",
       " '/Users/ericxia/anaconda/lib/python3.6/site-packages',\n",
       " '/Users/ericxia/Documents/Research/iRF/irf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.data, data.target, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00594245 0.01255127 0.         0.         0.         0.\n",
      " 0.         0.25097326 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00147196 0.         0.\n",
      " 0.         0.         0.02123834 0.00541967 0.33731042 0.05473207\n",
      " 0.00514887 0.         0.00098646 0.30422522 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "rf = wrf()\n",
    "weight = np.ones((X.shape[1],)) / X.shape[1]\n",
    "rf.fit(X, y, feature_weight=weight)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "input needs to be a recognizable object,         you have input a <class 'irf.ensemble.wrf.wrf'> object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c90e19c45e82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_rf_tree_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mirf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rf_tree_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36mget_rf_tree_data\u001b[0;34m(rf, X_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    523\u001b[0m     rf_validation_metrics = get_validation_metrics(inp_class_reg_obj=rf,\n\u001b[1;32m    524\u001b[0m                                                    \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                                                    X_test=X_test)\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Create a dictionary with all random forest metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36mget_validation_metrics\u001b[0;34m(inp_class_reg_obj, y_true, X_test)\u001b[0m\n\u001b[1;32m    229\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;34m\"DecisionTreeClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RandomForestClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RandomForestRegressor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DecisionTreeRegressor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         raise TypeError(\"input needs to be a recognizable object, \\\n\u001b[0;32m--> 231\u001b[0;31m         you have input a {} object\".format(type(inp_class_reg_obj)))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Get the predicted values on the validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: input needs to be a recognizable object,         you have input a <class 'irf.ensemble.wrf.wrf'> object"
     ]
    }
   ],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(leaf_node_paths, feature_paths):\n",
    "    leafnode_to_features = {}\n",
    "    for i in range(len(leaf_node_paths)):\n",
    "        leaf_node = leaf_node_paths[i][-1]\n",
    "        leafnode_to_features[leaf_node] = feature_paths[i]\n",
    "    return leafnode_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = np.array([])\n",
    "inp = X_train[y_train==1]\n",
    "\n",
    "for i in range(len(rf.estimators_)):\n",
    "    key = \"dtree\" + str(i)\n",
    "    tree_dict = all_rf_tree_data[key]\n",
    "    #assume that ith entry of feature_paths corresponds to ith entry of leaf_node_paths\n",
    "    feature_paths = tree_dict[\"all_uniq_leaf_paths_features\"]\n",
    "    leaf_nodes = tree_dict[\"all_leaf_nodes\"]\n",
    "    leaf_node_paths = tree_dict[\"all_leaf_node_paths\"]\n",
    "    decision_tree = rf.estimators_[i]\n",
    "    \n",
    "    end = decision_tree.apply(inp)\n",
    "    leafnode_to_features = convert(leaf_node_paths, feature_paths)\n",
    "    temp_features = np.vectorize(leafnode_to_features.get, otypes=[np.ndarray])(end)\n",
    "    interactions = np.concatenate((interactions, temp_features))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema = StructType([StructField(\"id\", IntegerType(), True), \n",
    "#                     StructField(\"list\", ArrayType(), True)])\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"iterative Random Forests with FP-Growth\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "input_list = [(i, interactions[i].tolist()) for i in range(len(interactions))]\n",
    "\n",
    "df = spark.createDataFrame(input_list, [\"id\", \"items\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.1, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "model.freqItemsets.show(40, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = [interactions[i].tolist() for i in range(len(interactions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we were used to do GraphLab\n",
    "import turicreate as tc\n",
    "ids = tc.SArray(list(range(len(inter))))\n",
    "vals = tc.SArray(inter)\n",
    "sf = tc.SFrame({'id':ids,'val':vals})\n",
    "model = tc.pattern_mining.create(sf, 'val',\n",
    "                features=['val'], min_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prefixspan import PrefixSpan\n",
    "ps = PrefixSpan(inter)\n",
    "ps.topk(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####WILL KILL THE KERNEL FOR SOME REASON\n",
    "stability_score = irf_utils.run_iRF(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    rf = rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_tree = pyfpgrowth.FPTree(inter, 0.9, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = fp_tree.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through signed iRF, check if it works with RIT code\n",
    "#Make sure the code currently works with the signed iRF\n",
    "#Play around with get_rf_tree_data method in iRF_utils to add signed support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_score = irf_utils.run_iRF_FPGrowth(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|items       |freq|\n",
      "+------------+----+\n",
      "|[20]        |116 |\n",
      "|[20, 22]    |65  |\n",
      "|[20, 22, 23]|40  |\n",
      "|[20, 22, 27]|54  |\n",
      "|[20, 23]    |63  |\n",
      "|[20, 23, 27]|51  |\n",
      "|[20, 7]     |73  |\n",
      "|[20, 7, 27] |54  |\n",
      "|[20, 27]    |97  |\n",
      "|[27]        |319 |\n",
      "|[21]        |96  |\n",
      "|[21, 22]    |57  |\n",
      "|[21, 22, 27]|47  |\n",
      "|[21, 23]    |65  |\n",
      "|[21, 23, 27]|54  |\n",
      "|[21, 7]     |51  |\n",
      "|[21, 27]    |77  |\n",
      "|[23]        |252 |\n",
      "|[23, 27]    |215 |\n",
      "|[22]        |247 |\n",
      "+------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stability_score.freqItemsets.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 27 is out of bounds for axis 0 with size 23",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5844ba2e4661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                     signed=True)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36mrun_iRF\u001b[0;34m(X_train, X_test, y_train, y_test, rf, rf_bootstrap, initial_weights, K, B, random_state_classifier, propn_n_samples, bin_class_type, M, max_depth, noisy_split, num_splits, signed)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             signed=signed)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run the RITs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36mget_rf_tree_data\u001b[0;34m(rf, X_train, X_test, y_test, signed)\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   \u001b[0mdtree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                                   \u001b[0mroot_node_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                                   signed=signed)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# Append output to our combined random forest outputs dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36mget_tree_data\u001b[0;34m(X_train, X_test, y_test, dtree, root_node_id, signed)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Get the total number of training samples used in each leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     all_leaf_node_samples = [n_node_samples[node_id].astype(int)\n\u001b[0;32m--> 447\u001b[0;31m                              for node_id in all_leaf_nodes]\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# Get proportion of training samples used in each leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Get the total number of training samples used in each leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     all_leaf_node_samples = [n_node_samples[node_id].astype(int)\n\u001b[0;32m--> 447\u001b[0;31m                              for node_id in all_leaf_nodes]\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# Get proportion of training samples used in each leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 27 is out of bounds for axis 0 with size 23"
     ]
    }
   ],
   "source": [
    "stability_score = irf_utils.run_iRF(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40),\n",
    "                                    signed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
