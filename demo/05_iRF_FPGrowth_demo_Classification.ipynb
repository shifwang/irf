{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of iRF classification\n",
    "\n",
    "* The following is a demo of the scikit learn iRF with FP-Growth code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required dependencies\n",
    "\n",
    "* In particular `irf_utils` and `irf_jupyter_utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericxia/anaconda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/Users/ericxia/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RandomForestClassifierWithWeights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b226197ff14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Needed for the scikit-learn wrapper function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mirf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mirf_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mirf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/iRF/irf/irf/irf_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Needed for the scikit-learn wrapper function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from .ensemble import (RandomForestClassifierWithWeights,\n\u001b[0m\u001b[1;32m     16\u001b[0m                        \u001b[0mRandomForestRegressorWithWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                        wrf, wrf_reg)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RandomForestClassifierWithWeights'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "# Needed for the scikit-learn wrapper function\n",
    "from irf import irf_utils\n",
    "from irf.ensemble import RandomForestClassifier\n",
    "from math import ceil\n",
    "\n",
    "# Import our custom utilities\n",
    "from imp import reload\n",
    "from irf import irf_jupyter_utils\n",
    "reload(irf_jupyter_utils)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fit the Initial Random Forest\n",
    "\n",
    "* Just fit every feature with equal weights per the usual random forest code e.g. DecisionForestClassifier in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, rf = irf_jupyter_utils.generate_rf_example(n_estimators=20, \n",
    "                                                                             feature_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training feature dimensions\", X_train.shape, sep = \":\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Training outcome dimensions\", y_train.shape, sep = \":\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Test feature dimensions\", X_test.shape, sep = \":\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Test outcome dimensions\", y_test.shape, sep = \":\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"first 2 rows of the training set features\", X_train[:2], sep = \":\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"first 2 rows of the training set outcomes\", y_train[:2], sep = \":\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get all Random Forest and Decision Tree Data\n",
    "\n",
    "* Extract in a single dictionary the random forest data and for all of it's decision trees\n",
    "* This is as required for FP-Growth purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(\n",
    "    rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Plot some Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Ranked Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "feature_importances_rank_idx = all_rf_tree_data['feature_importances_rank_idx']\n",
    "feature_importances = all_rf_tree_data['feature_importances']\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1\n",
    "                                   , feature_importances_rank_idx[f]\n",
    "                                   , feature_importances[feature_importances_rank_idx[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Ranked Feature Importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "feature_importances_std = all_rf_tree_data['feature_importances_std']\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1])\n",
    "        , feature_importances[feature_importances_rank_idx]\n",
    "        , color=\"r\"\n",
    "        , yerr = feature_importances_std[feature_importances_rank_idx], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), feature_importances_rank_idx)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree 0 (First) - Get output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output against the decision tree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the trees individually\n",
    "irf_jupyter_utils.draw_tree(decision_tree = all_rf_tree_data['rf_obj'].estimators_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the iRF function\n",
    "\n",
    "We will run the iRF FP-Growth with the following **parameters**\n",
    "\n",
    "#### Data:\n",
    "* breast cancer binary classification data\n",
    "* **random state (for reproducibility):** 2018\n",
    "\n",
    "#### Weighted RFs\n",
    "* **K:** 5 iterations\n",
    "* **number of trees:** 20\n",
    "\n",
    "#### Bootstrap RFs\n",
    "* **proportion of bootstrap samples:** 20%\n",
    "* **B:** 30 bootstrap samples\n",
    "* **number of trees (bootstrap RFs):** 5 iterations\n",
    "\n",
    "#### FP-Growth (on the bootstrap RFs)\n",
    "* **min_support:** 0.05 (interaction must occur 5% of the time to be returned by FP-Growth)\n",
    "* **min_confidence:** 0.8 (irrelevant currently for iRF purposes but maybe useful for others)\n",
    "* **bootstrap_num:** 20 (for each bootstrap sample, saves top 10 interactions and then computes stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the iRF is easy - single function call\n",
    "\n",
    "* All of the bootstrap, RIT complexity is covered through the key parameters passed through\n",
    "in the main algorithm (as listed above)\n",
    "* This function call returns the following data:\n",
    "    1. all RF weights\n",
    "    2. all the K RFs that are iterated over\n",
    "    3. all of the B bootstrap RFs that are run\n",
    "    4. all the B*M RITs that are run on the bootstrap RFs\n",
    "    5. the stability score\n",
    "    \n",
    "### This is a lot of data returned!\n",
    "\n",
    "Will be useful when we build the **interface** later\n",
    "\n",
    "### Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rf_weights, all_K_iter_rf_data, \\\n",
    "all_rf_bootstrap_output, all_rit_bootstrap_output, \\\n",
    "stability_score = irf_utils.run_iRF_FPGrowth(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40),\n",
    "                                    B=30,\n",
    "                                    random_state_classifier=2018,\n",
    "                                    propn_n_samples=.2,\n",
    "                                    bin_class_type=1,\n",
    "                                    min_support=0.05,\n",
    "                                    min_confidence=0.8,\n",
    "                                    bootstrap_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the stability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_jupyter_utils._get_histogram(stability_score, sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Stability Scores between RIT iRF and FP-Growth iRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, rit_stability_score = irf_utils.run_iRF(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40),\n",
    "                                    B=30,\n",
    "                                    random_state_classifier=2018,\n",
    "                                    propn_n_samples=.2,\n",
    "                                    bin_class_type=1,\n",
    "                                    M=20,\n",
    "                                    max_depth=5,\n",
    "                                    noisy_split=False,\n",
    "                                    num_splits=2,\n",
    "                                    signed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsigned_to_output(path):\n",
    "    temp = path.split(\"_\")\n",
    "    features = [int(elem) for elem in temp]\n",
    "    features.sort()\n",
    "    features = [str(elem) for elem in features]\n",
    "    output = \"_\".join(features)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "conversion = defaultdict(list)\n",
    "rit_interactions = []\n",
    "interactions = []\n",
    "\n",
    "for inter in stability_score.keys():\n",
    "    conversion[unsigned_to_output(inter)].append(inter)\n",
    "    rit_interactions.append(unsigned_to_output(inter))\n",
    "    \n",
    "for inter in rit_stability_score.keys():\n",
    "    conversion[unsigned_to_output(inter)].append(inter)\n",
    "    interactions.append(unsigned_to_output(inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rit_interactions = set(rit_interactions)\n",
    "interactions = set(interactions)\n",
    "\n",
    "print(\"The number of RIT interactions are:\")\n",
    "print(len(interactions))\n",
    "\n",
    "print(\"The number of FP-Growth interactions are:\")\n",
    "print(len(rit_interactions))\n",
    "\n",
    "print(\"The number of interactions in common are:\")\n",
    "print(len(rit_interactions.intersection(interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both RIT and FP-Growth are returning many interactions in common, and most of the FP-Growth interactions are ones also found by RIT. However RIT iRF is returning more interactions as compared to FP-Growth, but this can easily be adjusted by changing the min_support parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rit_sta = []\n",
    "fp_sta = []\n",
    "feature_paths = []\n",
    "\n",
    "data_x = rit_stability_score.keys()\n",
    "data_x = sorted(rit_stability_score, key=rit_stability_score.get,\n",
    "                        reverse=True)\n",
    "\n",
    "for inter in data_x:\n",
    "    index = unsigned_to_output(inter)\n",
    "    rit_sta.append(rit_stability_score[index])\n",
    "    all_inter = conversion[index]\n",
    "    if len(all_inter) == 1:\n",
    "        fp_sta.append(0)\n",
    "    else:\n",
    "        index = all_inter.index(inter)\n",
    "        temp = all_inter[:index] + all_inter[index+1:]\n",
    "        fp_sta.append(stability_score[temp[0]])\n",
    "    feature_paths.append(inter)\n",
    "    \n",
    "for inter in stability_score.keys():\n",
    "    index = unsigned_to_output(inter)\n",
    "    all_inter = conversion[index]\n",
    "    if len(all_inter) == 1:\n",
    "        rit_sta.append(0)\n",
    "        fp_sta.append(stability_score[all_inter[0]])\n",
    "        feature_paths.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# code copied from stack overflow\n",
    "def subcategorybar(X, vals, width=0.8):\n",
    "    n = len(vals)\n",
    "    _X = np.arange(len(X))\n",
    "    plt.bar(_X - width/2. + 0/float(n)*width, vals[0], \n",
    "            width=width/float(n), align=\"edge\", label=\"RIT\") \n",
    "    plt.bar(_X - width/2. + 1/float(n)*width, vals[1], \n",
    "            width=width/float(n), align=\"edge\", label=\"FP-Growth\")   \n",
    "    #plt.xticks(_X, X)\n",
    "    \n",
    "subcategorybar(feature_paths, [rit_sta, fp_sta])\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel(\"Stability Score\")\n",
    "plt.title(\"Stability Scores of Features Paths, RIT iRF vs FP-Growth iRF\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every interaction that iRF with RIT returns, its stability score is plotted in blue, and right next to it in orange is the corresponding FP-Growth stability score for the feature. A few things to point out, it seems that FP-Growth has a tendency to have higher stability scores for the interactions that the two find in common. In addition, some of the interactions that FP-Growth find but RIT doesn't (or RIT assigns low stability scores for) FP-Growth gives fairly high stability scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "_, _, _, _, _ = irf_utils.run_iRF(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40),\n",
    "                                    B=30,\n",
    "                                    random_state_classifier=2018,\n",
    "                                    propn_n_samples=.2,\n",
    "                                    bin_class_type=1,\n",
    "                                    M=20,\n",
    "                                    max_depth=5,\n",
    "                                    noisy_split=False,\n",
    "                                    num_splits=2,\n",
    "                                    signed=False)\n",
    "end = time.time()\n",
    "RIT_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "_, _, _, _, _ = irf_utils.run_iRF_FPGrowth(X_train=X_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_train=y_train,\n",
    "                                    y_test=y_test,\n",
    "                                    K=5,\n",
    "                                    rf=RandomForestClassifier(n_estimators=40),\n",
    "                                    B=30,\n",
    "                                    random_state_classifier=2018,\n",
    "                                    propn_n_samples=.2,\n",
    "                                    bin_class_type=1,\n",
    "                                    min_support=0.05,\n",
    "                                    min_confidence=0.8,\n",
    "                                    bootstrap_num=20)\n",
    "end = time.time()\n",
    "FPGrowth_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = (RIT_time, FPGrowth_time)\n",
    "objects = (\"RIT\", \"FP-Growth\")\n",
    "\n",
    "plt.bar([0, 1], time, align='center', alpha=0.5)\n",
    "plt.xticks([0,1], objects)\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('iRF Time to Run')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP-Growth is about 5 seconds slower (25% slower), but most of this is likely due to overheard for intializing Spark. Would need to run on datasets increasing in size to see overall performance trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Enhancements: Instead of getting all the interactions that have greater than some specified support, there are algorithms (TFP) based on FP-Growth that are able to return the top $k$ closed interaction sets. This would likely provide substantial speedup and would not require the user to pre-specify the required minimum support. However the issue is that there is no publicly available implementation of such algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
