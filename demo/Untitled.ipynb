{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import irf\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "import irf.ensemble.wrf as wrf\n",
    "from irf.ensemble.wrf import wrf_reg\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from irf import irf_utils\n",
    "from irf import irf_jupyter_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.data, data.target, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.00706097  0.11343517  0.          0.          0.          0.          0.\n",
      "  0.00615402  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.04457264  0.31979639  0.21288434  0.          0.          0.\n",
      "  0.29609648  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "rf = wrf()\n",
    "weight = np.ones((X.shape[1],)) / X.shape[1]\n",
    "rf.fit(X, y, feature_weight=weight)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(leaf_node_paths, feature_paths):\n",
    "    leafnode_to_features = {}\n",
    "    for i in range(len(leaf_node_paths)):\n",
    "        leaf_node = leaf_node_paths[i][-1]\n",
    "        leafnode_to_features[leaf_node] = feature_paths[i]\n",
    "    return leafnode_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = np.array([])\n",
    "inp = X_train[y_train==1]\n",
    "\n",
    "for i in range(len(rf.estimators_)):\n",
    "    key = \"dtree\" + str(i)\n",
    "    tree_dict = all_rf_tree_data[key]\n",
    "    #assume that ith entry of feature_paths corresponds to ith entry of leaf_node_paths\n",
    "    feature_paths = tree_dict[\"all_uniq_leaf_paths_features\"]\n",
    "    leaf_nodes = tree_dict[\"all_leaf_nodes\"]\n",
    "    leaf_node_paths = tree_dict[\"all_leaf_node_paths\"]\n",
    "    decision_tree = rf.estimators_[i]\n",
    "    \n",
    "    end = decision_tree.apply(inp)\n",
    "    leafnode_to_features = convert(leaf_node_paths, feature_paths)\n",
    "    temp_features = np.vectorize(leafnode_to_features.get, otypes=[np.ndarray])(end)\n",
    "    interactions = np.concatenate((interactions, temp_features))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|          items|\n",
      "+---+---------------+\n",
      "|  0|[7, 21, 23, 27]|\n",
      "|  1|[7, 21, 23, 27]|\n",
      "|  2|    [7, 21, 27]|\n",
      "|  3|[7, 21, 23, 27]|\n",
      "|  4|[7, 21, 23, 27]|\n",
      "|  5|[7, 21, 23, 27]|\n",
      "|  6|[7, 21, 23, 27]|\n",
      "|  7|[7, 21, 23, 27]|\n",
      "|  8|   [21, 23, 27]|\n",
      "|  9|[7, 21, 23, 27]|\n",
      "| 10|[7, 21, 23, 27]|\n",
      "| 11|[7, 21, 23, 27]|\n",
      "| 12|[7, 21, 23, 27]|\n",
      "| 13|[7, 21, 23, 27]|\n",
      "| 14|[7, 21, 23, 27]|\n",
      "| 15|[7, 21, 23, 27]|\n",
      "| 16|[7, 21, 23, 27]|\n",
      "| 17|[7, 21, 23, 27]|\n",
      "| 18|   [21, 23, 27]|\n",
      "| 19|[7, 21, 23, 27]|\n",
      "+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema = StructType([StructField(\"id\", IntegerType(), True), \n",
    "#                     StructField(\"list\", ArrayType(), True)])\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"iterative Random Forests with FP-Growth\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "input_list = [(i, interactions[i].tolist()) for i in range(len(interactions))]\n",
    "\n",
    "df = spark.createDataFrame(input_list, [\"id\", \"items\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+\n",
      "|items           |freq|\n",
      "+----------------+----+\n",
      "|[7]             |1036|\n",
      "|[7, 23]         |991 |\n",
      "|[7, 23, 27]     |735 |\n",
      "|[7, 21]         |458 |\n",
      "|[7, 21, 23]     |429 |\n",
      "|[7, 21, 23, 27] |399 |\n",
      "|[7, 21, 27]     |424 |\n",
      "|[7, 27]         |772 |\n",
      "|[27]            |2933|\n",
      "|[13]            |645 |\n",
      "|[13, 22]        |355 |\n",
      "|[13, 22, 27]    |355 |\n",
      "|[13, 23]        |361 |\n",
      "|[13, 23, 27]    |361 |\n",
      "|[13, 27]        |645 |\n",
      "|[23]            |2870|\n",
      "|[23, 27]        |2612|\n",
      "|[22]            |1451|\n",
      "|[22, 23]        |1134|\n",
      "|[22, 23, 27]    |1104|\n",
      "|[22, 27]        |1412|\n",
      "|[21]            |1444|\n",
      "|[21, 22]        |997 |\n",
      "|[21, 22, 23]    |699 |\n",
      "|[21, 22, 23, 27]|671 |\n",
      "|[21, 22, 27]    |965 |\n",
      "|[21, 23]        |1133|\n",
      "|[21, 23, 27]    |1103|\n",
      "|[21, 27]        |1410|\n",
      "+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.1, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "model.freqItemsets.show(40, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
